{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pivotal determinant influencing an actor's career trajectory is their proficiency in embodying a diverse array of characters, serving as a gauge of their versatile talent. To assess the spectrum of personas portrayed by actors in our dataset, we employed the methodology outlined by Bamman, O'Connor, and Smith in their paper titled \"Learning Latent Personas of Film Characters\" (ACL 2013)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code that we used clusters the dataset into 50 personas, and for each character assigns a probability of belonging to a particular cluster\n",
    "\n",
    "persona_proba_file_path='./data/25.100.lda.log.txt'\n",
    "proba_columns=[f'proba_{p}' for p in range(1, 51)]\n",
    "columns=['e.id','Wikipedia Movie id','Movie name', 'charName', 'fullName' , 'occurrences', 'max', 'probas']\n",
    "persona_prob_df=pd.read_csv(persona_proba_file_path, sep='\\t', header=None, names=columns)\n",
    "persona_prob_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persona_prob_df['probas'] = persona_prob_df['probas'].str.split()\n",
    "persona_prob_df[proba_columns] = pd.DataFrame(persona_prob_df['probas'].tolist(), dtype=float)\n",
    "persona_prob_df = persona_prob_df.drop(columns=['probas'])\n",
    "persona_prob_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the obtained dataframe we have the associates probability verctor to each character or entity in each movie. In order to use this dataset and cobine it with characters dataframes we perform a filtering on the characters for which the \"char/actor freebase id\" is known. The latter starst with \"/m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persona_prob_df['e.id'].apply(lambda x: x.startswith('/m'))\n",
    "persona_proba_filtered=persona_prob_df.loc[persona_prob_df['e.id'].apply(lambda x: x.startswith('/m'))]\n",
    "persona_proba_filtered.reset_index(inplace=True)\n",
    "persona_proba_filtered=persona_proba_filtered.drop(['index'], axis=1)\n",
    "persona_proba_filtered.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to associate one persona to each character, therefore we keep only the persona with the greatest probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "max_proba = []\n",
    "for i in tqdm(range(persona_proba_filtered.shape[0])):\n",
    "    row = persona_proba_filtered[proba_columns].iloc[i] \n",
    "    max_idx = row.argmax()   \n",
    "    max_proba.append(row.index[max_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persona_proba_filtered['Persona']=max_proba\n",
    "persona_df=persona_proba_filtered.drop(proba_columns, axis=1)\n",
    "persona_df['Persona']=persona_df['Persona'].apply(lambda x: x.split('_')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_characters = pd.read_table('~/ADA2023/Project/Data/MovieSummaries/character.metadata.tsv', header=None)\n",
    "all_characters = pd.read_csv('Data/MovieSummaries/character.metadata.tsv', sep='\\t', header=None)\n",
    "all_characters.columns = ['Wikipedia movie ID', 'Freebase movie ID', 'Movie release date','Character name','Actor date of birth','Actor gender','Actor height','Actor ethnicity','Actor name','Actor age at movie release','Freebase character/actor map ID','Freebase character ID','Freebase actor ID']\n",
    "all_characters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the obtained persona dataframe with the characters dataframe\n",
    "merged_persona_character=pd.merge(all_characters, persona_df, left_on='Freebase character/actor map ID', right_on='e.id')\n",
    "merged_persona_character.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_persona_character.to_csv('persona_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
